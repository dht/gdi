# Future Development

GDI mission is to create a new generation of interfaces and explore how these interfaces operate, look, and feel. While desktop web interfaces are the current focus, GDI aims to be device agnostic and extend to mobile, VR, AR, and wearable technologies. AI would come in many forms and shapes and interfaces will play a key role in how we interact with AI.

Future Human-AI interaction can be divided according to the level of autonomy of the AI:

1. **Autonomous Agents**: background process. AI is the driver.
2. **Toolbox**: AI tools that augment human capabilities. Person is the driver.
3. **Hybrid**: AI and human work together. Both are drivers and both are passengers.

Lets explore each type in more detail and elaborate on the challenges when it comes to building interfaces.

## Type #1: Autonomous Agents

AI agents that can operate independently and make decisions on their own. They can be used to automate tasks and make decisions on behalf of humans. An example can be a food-ordering agent that can order food from a convenience store on behalf of a human and take in consideration the human's preferences and dietary restrictions.

### Interface Challenges

Interfaces in this category will enable the user to:

1. Configure the agent: how to configure the agent to operate in a way that is aligned with the human's preferences and goals.
2. Monitoring the agent: how to monitor the agent and make sure it is operating as expected.
3. Reporting: how to report the agent's activity and results to the human.

## Type #2: Toolbox

AI tools that augment human capabilities. ChatGPT is an example of such a tool. Invoked with a prompt, it generates a response. It can be used for endless applications such as generating text, code, and more.

This category is the main focus of GDI at the moment.

### Interface Challenges

While chat-based interfaces proved to be extremely versatile, the textual and time-based nature of them has limitations and challenges:

- **Context management**: as the conversation grows, it becomes harder to manage the context and keep track of the conversation history.
- **Signal/noise distinction**: it is hard for the user to hand pick the signal, the data which has relevance for the user, from the noise, the data which is not relevant for the user.
- **Data management**: it is hard to manage the data that is generated by the AI tool. For instance, if the user wants to save a specific response, it is hard to do so in a chat-based interface.
- **Complex workflows**: it is hard to create complex workflows in a chat-based interface. For instance, if the user wants to create a flow that involves multiple AI tools, it is hard to do so in a chat-based interface.
- **Complex applications**: it is hard to create complex applications in a chat-based interface. For instance, a 3d modeling application.

GDI aims to address these challenges and others by creating a new generation of graphic interfaces.

## Type #3: Hybrid

AI and human work together. Both are drivers and both are passengers. In the context of post-AGI, this category raises some semi-philosophical questions such as:

- How does the switch between AI and human happen?
- Does the AI tune down it's so-called RPM to match the human's RPM?

However, in current pre-AGI times, this fascinating category can still be explored. In the context of GDI this can be done by allowing multiple flows to run in parallel and starting to examine how human-AI team work might look like.

### Interface Challenges

Interfaces in this category will enable the user to "launch and forget" flows.

Interface in this category may enable the user to :

- Know Which AI flows are running?
  - What is the current state of each flow?
  - What is the estimated time of completion for each flow?
  - What is the current cost of each flow?
  - Error management: what happens when a flow fails?
- Define post flow actions in similar ways that services such as IFTTT and Zapier do.
- Train and tweak configurations of AI flows.
- Create complex workflows that involve multiple AI flows.

In essence this category is about creating a multi agent system where the orchestration and integration is done by the user.

<img src="https://raw.githubusercontent.com/dht/gdi-assets/main/assets/images/docs/5.png" width="100%"/>
